{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcriber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shlex\n",
    "import wave\n",
    "import numpy as np\n",
    "import random\n",
    "from deepspeech import Model, printVersions\n",
    "from timeit import default_timer as timer\n",
    "import IPython.display as ipd\n",
    "import subprocess\n",
    "try:\n",
    "    from shhlex import quote\n",
    "except ImportError:\n",
    "    from pipes import quote\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = '/opt/shared/models/'\n",
    "audio_dir = '/opt/shared_data/cpm_wav_cut/'\n",
    "lm_path = '/opt/shared/lm.binary'\n",
    "trie_path = '/opt/shared/trie'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a Model\n",
    "Load the best model from the model directory and load it with specified LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = sorted(os.listdir(models_dir))[0]\n",
    "load_start = timer()\n",
    "ds = Model(os.path.join(models_dir, best_model), aBeamWidth=1024)\n",
    "ds.enableDecoderWithLM(lm_path, trie_path, 0.75, 1.85)\n",
    "load_end = load_start - timer()\n",
    "print('Loaded', best_model, 'in', load_end)\n",
    "desired_sr = ds.sampleRate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the audio directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = os.listdir(audio_dir)\n",
    "print(audio_files[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling function\n",
    "Inspired by DeepSpeech function \"convert_samplerate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(path, samplerate):\n",
    "    sox_cmd = 'sox {} --type raw --bits 16 --channels 1 --rate {} --encoding signed-integer --endian little --compression 0.0 --no-dither - '.format(quote(path), samplerate)\n",
    "    output = subprocess.check_output(shlex.split(sox_cmd), stderr=subprocess.PIPE)\n",
    "    return np.frombuffer(output, np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference test\n",
    "Picks a random audio file and runs an inference on it. You can then listen to the original audio for a comparison!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(model, audio):\n",
    "    audio_wave = wave.open(audio, 'rb')\n",
    "    desired_samplerate = model.sampleRate()\n",
    "    if audio_wave.getframerate() != desired_samplerate:\n",
    "        audio = resample(audio, desired_samplerate)\n",
    "    else:\n",
    "        audio = np.frombuffer(audio_wave.readframes(audio_wave.getnframes()), np.int16)\n",
    "    return model.stt(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_audio_file = random.choice(audio_files)\n",
    "random_audio_full = os.path.join(audio_dir, random_audio_file)\n",
    "    \n",
    "print(random_audio_file + ': ')\n",
    "print(run_inference(ds, random_audio_full))\n",
    "display(ipd.Audio(random_audio_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = '/opt/speech2text/dataset_sample'\n",
    "if not os.path.exists(target_dir): os.mkdir(target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_files = 100\n",
    "random_files_sample = random.sample(audio_files, num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_csv = open(os.path.join(target_dir, 'data.csv'), 'w+', encoding='utf-8')\n",
    "data_csv.write('wav_filename,wav_filesize,transcript' + '\\n')\n",
    "\n",
    "cnt = 1\n",
    "for f in random_files_sample:\n",
    "    full_f = os.path.join(audio_dir, f)\n",
    "    full_target = os.path.join(target_dir, f)\n",
    "    f_size = os.stat(full_f).st_size\n",
    "    label = run_inference(ds, full_f)\n",
    "    data_csv.write(str(full_f) + ',' + str(f_size) + ',' + str(label) + '\\n')\n",
    "    copyfile(full_f, full_target)\n",
    "    print(cnt, '/', num_files)\n",
    "    cnt += 1\n",
    "\n",
    "data_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
